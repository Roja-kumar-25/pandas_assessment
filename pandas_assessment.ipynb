{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How to import pandas and check the version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How to create a series from a list, numpy array and dict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "4    e\n",
      "dtype: object\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "dtype: int64\n",
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "d    3\n",
      "e    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mylist=list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "myarr=np.arange(26)\n",
    "mydict=dict(zip(mylist,myarr))\n",
    "\n",
    "print(pd.Series(mylist).head())\n",
    "print(pd.Series(myarr).head())\n",
    "print(pd.Series(mydict).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How to convert the index of a series into a column of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index   0\n",
      "0      a   0\n",
      "1      b   1\n",
      "2      c   2\n",
      "3      d   3\n",
      "4      e   4\n",
      "5      f   5\n",
      "6      g   6\n",
      "7      h   7\n",
      "8      i   8\n",
      "9      j   9\n",
      "10     k  10\n",
      "11     l  11\n",
      "12     m  12\n",
      "13     n  13\n",
      "14     o  14\n",
      "15     p  15\n",
      "16     q  16\n",
      "17     r  17\n",
      "18     s  18\n",
      "19     t  19\n",
      "20     u  20\n",
      "21     v  21\n",
      "22     w  22\n",
      "23     x  23\n",
      "24     y  24\n",
      "25     z  25\n"
     ]
    }
   ],
   "source": [
    "ser=pd.Series(mydict)\n",
    "df=ser.to_frame().reset_index()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. How to combine many series to form a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2\n",
      "0  a   0\n",
      "1  b   1\n",
      "2  c   2\n",
      "3  d   3\n",
      "4  e   4\n"
     ]
    }
   ],
   "source": [
    "ser1=pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n",
    "ser2=pd.Series(np.arange(26))\n",
    "df=pd.DataFrame({'c1':ser1,\"c2\":ser2})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How to assign name to the series’ index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "4    e\n",
      "Name: alphabets, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ser=pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n",
    "ser.name=\"alphabets\"\n",
    "print(ser.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. How to get the items not common to both series A and series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 6, 7, 8}\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "s1=set(ser1)\n",
    "s2=set(ser2)\n",
    "res=s1.symmetric_difference(s2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum: 0.12966039212199476\n",
      "25th percentile: 6.862687426527527\n",
      "median: 8.426893079761792\n",
      "75th percentile: 11.728333904128037\n",
      "maximum: 23.169906832067227\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.normal(10, 5, 25))\n",
    "print(\"minimum:\",ser.min())\n",
    "print(\"25th percentile:\",ser.quantile(0.25))\n",
    "print(\"median:\",ser.median())\n",
    "print(\"75th percentile:\",ser.quantile(0.75))\n",
    "print(\"maximum:\",ser.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. How to get frequency counts of unique items of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b    7\n",
      "h    5\n",
      "a    4\n",
      "d    4\n",
      "g    3\n",
      "f    3\n",
      "c    2\n",
      "e    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "print(ser.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         4\n",
      "1         4\n",
      "2     other\n",
      "3         3\n",
      "4         3\n",
      "5         4\n",
      "6         3\n",
      "7         4\n",
      "8     other\n",
      "9         4\n",
      "10    other\n",
      "11        3\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "top_2=ser.value_counts().nlargest(2).index\n",
    "res=ser.where(ser.isin(top_2),other='other')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. How to bin a numeric series to 10 groups of equal size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      4th\n",
      "1      3th\n",
      "2      2th\n",
      "3      3th\n",
      "4     10th\n",
      "5      7th\n",
      "6      5th\n",
      "7      5th\n",
      "8      1th\n",
      "9      4th\n",
      "10     8th\n",
      "11     9th\n",
      "12     6th\n",
      "13     8th\n",
      "14     1th\n",
      "15     9th\n",
      "16     2th\n",
      "17     7th\n",
      "18    10th\n",
      "19     6th\n",
      "dtype: category\n",
      "Categories (10, object): ['1th' < '2th' < '3th' < '4th' ... '7th' < '8th' < '9th' < '10th']\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.random(20))\n",
    "# print(ser.head())\n",
    "print(pd.qcut(ser,10,labels=[f'{i+1}th' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. How to convert a numpy array to a dataframe of given shape? (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 2 9 7]\n",
      " [8 1 4 6 6]\n",
      " [1 9 7 8 7]\n",
      " [7 8 3 2 1]\n",
      " [9 7 3 7 1]\n",
      " [6 6 1 1 7]\n",
      " [3 2 9 2 7]]\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "reshape_ser=ser.values.reshape((7,5))\n",
    "print(reshape_ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. How to find the positions of numbers that are multiples of 3 from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "print(np.argwhere(ser%3==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. How to extract items at given positions from a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "e\n",
      "i\n",
      "o\n",
      "u\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "4     e\n",
       "8     i\n",
       "14    o\n",
       "20    u\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "for i in pos:\n",
    "    print(ser[i])\n",
    "    #or\n",
    "ser.take(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. How to stack two series vertically and horizontally ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index value\n",
      "0      0     a\n",
      "1      1     b\n",
      "2      2     c\n",
      "3      3     d\n",
      "4      4     e\n",
      "   0  1\n",
      "0  0  a\n",
      "1  1  b\n",
      "2  2  c\n",
      "3  3  d\n",
      "4  4  e\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "df=pd.DataFrame({\"index\":ser1,\"value\":ser2})\n",
    "print(df)\n",
    "# ser1.append(ser2)\n",
    "df=pd.concat([ser1,ser2],axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. How to get the positions of items of series A in another series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 0, 8]\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "ind=[pd.Index(ser1).get_loc(i) for i in ser2]\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. How to compute the mean squared error on a truth and predicted series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "dtype: int64\n",
      "0    0.497334\n",
      "1    1.226948\n",
      "2    2.058249\n",
      "3    3.818912\n",
      "4    4.475112\n",
      "dtype: float64\n",
      "1.9133179446881925\n"
     ]
    }
   ],
   "source": [
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "# print(truth.head())\n",
    "# print(pred.head())\n",
    "print((sum(truth-pred)**2)/len(truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. How to convert the first character of each element in a series to uppercase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How', 'To', 'Kick', 'Ass?']\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "l1=[]\n",
    "for i in range(len(ser)):\n",
    "    l1.append(ser[i][0].upper()+ser[i][1:])\n",
    "print(l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. How to calculate the number of characters in each word in a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3\n",
      "1    2\n",
      "2    4\n",
      "3    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "res=ser.map(lambda val :len(val))\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. How to compute difference of differences between consequtive numbers of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    NaN\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "5    1.0\n",
      "6    0.0\n",
      "7    2.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "print(ser.diff().diff())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. How to convert a series of date-strings to a timeseries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2010-01-01 00:00:00\n",
      "1   2011-02-02 00:00:00\n",
      "2   2012-03-03 00:00:00\n",
      "3   2013-04-04 00:00:00\n",
      "4   2014-05-05 00:00:00\n",
      "5   2015-06-06 12:20:00\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "ser_parse=ser.map(lambda x:parse(x))\n",
    "print(pd.to_datetime(ser_parse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. How to get the day of month, week number, day of year and day of week from a series of date strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [1, 2, 3, 4, 5, 6]\n",
      "Week number:  [53, 5, 9, 14, 19, 23]\n",
      "Day number of year:  [1, 33, 63, 94, 125, 157]\n",
      "Day of week:  ['Friday', 'Wednesday', 'Saturday', 'Thursday', 'Monday', 'Saturday']\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "from dateutil.parser import parse\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "print(\"Date: \", ser_ts.dt.day.tolist())\n",
    "print(\"Week number: \", ser_ts.dt.isocalendar().week.tolist())#learned\n",
    "print(\"Day number of year: \", ser_ts.dt.dayofyear.tolist())\n",
    "print(\"Day of week: \", ser_ts.dt.day_name().tolist())#learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. How to convert year-month string to dates corresponding to the 4th day of the month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates taht start with 4th of each month: 0   2010-01-04\n",
      "1   2011-02-04\n",
      "2   2012-03-04\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "from dateutil.parser import parse \n",
    "set_set=ser.map(lambda x:parse(x).replace(day=4))\n",
    "print(\"dates taht start with 4th of each month:\",set_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. How to filter words that contain atleast 2 vowels from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Apple\n",
      "1    Orange\n",
      "4     Money\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "res= ser[ser.str.findall(r'[aeiouAEIOU]').str.len()>=2]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. How to filter valid emails from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rameses@egypt.com', 'matt@t.co', 'narendra@modi.com']\n",
      "0                     []\n",
      "1    [rameses@egypt.com]\n",
      "2            [matt@t.co]\n",
      "3    [narendra@modi.com]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "l=[]\n",
    "for i in range(len(emails)):\n",
    "    if \"@\" in emails[i]:\n",
    "        l.append(emails[i])\n",
    "print(l)\n",
    "#or\n",
    "print(emails.str.findall(pattern,re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. How to get the mean of a series grouped by another series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "['apple', 'apple', 'banana', 'banana', 'apple', 'apple', 'carrot', 'apple', 'carrot', 'apple']\n",
      "   fruits  weights\n",
      "0   apple      1.0\n",
      "1   apple      2.0\n",
      "2  banana      3.0\n",
      "3  banana      4.0\n",
      "4   apple      5.0\n",
      "5   apple      6.0\n",
      "6  carrot      7.0\n",
      "7   apple      8.0\n",
      "8  carrot      9.0\n",
      "9   apple     10.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruits</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carrot</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         weights\n",
       "fruits          \n",
       "apple   5.333333\n",
       "banana  3.500000\n",
       "carrot  8.000000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "print(weights.tolist())\n",
    "print(fruit.tolist())\n",
    "fruits_weights_df=pd.DataFrame({\"fruits\":fruit,\"weights\":weights})\n",
    "print(fruits_weights_df)\n",
    "fruits_weights_df.groupby(\"fruits\").mean(\"weights\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. How to compute the euclidean distance between two series?WITHOUT USING PACKAGED FORMULA(SQRT(X2-X1)**2+(Y2-Y1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.16590212458495\n"
     ]
    }
   ],
   "source": [
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "e_dist=np.linalg.norm(p-q)\n",
    "print(e_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28. How to find all the local maxima (or peaks) in a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "# res=[]\n",
    "# for i in range(len(ser)):\n",
    "#     if ser[i-1]<ser[i] and ser[i+1]<ser[i]:\n",
    "#         res.append(ser.index(i))\n",
    "# print(res)\n",
    "dd = np.diff(np.sign(np.diff(ser)))\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29. How to replace missing spaces in a string with the least frequent character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbccdebcabedcgade\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "my_str = 'dbc deb abed gade'\n",
    "res= Counter(my_str)\n",
    "res=min(res,key=res.get)\n",
    "print(my_str.replace(\" \",res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01    3\n",
      "2000-01-08    8\n",
      "2000-01-15    2\n",
      "2000-01-22    7\n",
      "2000-01-29    7\n",
      "2000-02-05    0\n",
      "2000-02-12    9\n",
      "2000-02-19    6\n",
      "2000-02-26    7\n",
      "2000-03-04    5\n",
      "Freq: W-SAT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dates=pd.date_range(\"2000-01-01\",periods=10,freq=\"W-SAT\")\n",
    "values=np.random.randint(0,10,size=10)\n",
    "\n",
    "df=pd.Series(values,index=dates)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-08     NaN\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02    10.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04     3.0\n",
       "2000-01-05     3.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     3.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "print(ser)\n",
    "# Input\n",
    "ser = pd.Series([1,10,3, np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "\n",
    "# Solution\n",
    "ser.resample('D').ffill()  # fill with previous value\n",
    "\n",
    "# Alternatives\n",
    "ser.resample('D').bfill()  # fill with next value\n",
    "ser.resample('D').bfill().ffill()  # fill next else prev value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32. How to compute the autocorrelations of a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(-0.05), np.float64(0.28), np.float64(0.02), np.float64(0.23), np.float64(-0.1), np.float64(0.22), np.float64(0.14), np.float64(0.44), np.float64(-0.27), np.float64(0.59)]\n",
      "Lag having highest correlation:  10\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "# Input\n",
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "\n",
    "# Solution\n",
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "print(autocorrelations[1:])\n",
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33. How to import only every nth row from a csv file to create a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61865/2575011344.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Solution 2: Use chunks and list comprehension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.DataFrame()\n",
    "for chunk in df:\n",
    "    df2 = df2.append(chunk.iloc[0,:])\n",
    "\n",
    "\n",
    "# Solution 2: Use chunks and list comprehension\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.concat([chunk.iloc[0] for chunk in df], axis=1)\n",
    "df2 = df2.transpose()\n",
    "\n",
    "# Solution 3: Use csv reader\n",
    "import csv          \n",
    "with open('BostonHousing.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if i%50 == 0:\n",
    "            out.append(row)\n",
    "\n",
    "df2 = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34. How to change column values when importing csv to a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BostonHousing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Solution 2: Using csv reader\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBostonHousing.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[1;32m      9\u001b[0m     out \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BostonHousing.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv',  \n",
    "                 converters={'medv': lambda x: 'High' if float(x) > 25 else 'Low'})\n",
    "\n",
    "\n",
    "# Solution 2: Using csv reader\n",
    "import csv\n",
    "with open('BostonHousing.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if i > 0:\n",
    "            row[13] = 'High' if float(row[13]) > 25 else 'Low'\n",
    "        out.append(row)\n",
    "\n",
    "df = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35. How to create a dataframe with rows as strides from a given series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 2,  3,  4,  5],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [10, 11, 12, 13]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = pd.Series(range(15))\n",
    "# L = pd.Series(range(15))\n",
    "\n",
    "def gen_strides(a, stride_len=5, window_len=5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len=2, window_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36. How to import only specified columns from a csv file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  medv\n",
      "0  0.00632  24.0\n",
      "1  0.02731  21.6\n",
      "2  0.02729  34.7\n",
      "3  0.03237  33.4\n",
      "4  0.06905  36.2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', usecols=['crim', 'medv'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 27)\n",
      "Manufacturer           object\n",
      "Model                  object\n",
      "Type                   object\n",
      "Min.Price             float64\n",
      "Price                 float64\n",
      "Max.Price             float64\n",
      "MPG.city              float64\n",
      "MPG.highway           float64\n",
      "AirBags                object\n",
      "DriveTrain             object\n",
      "Cylinders              object\n",
      "EngineSize            float64\n",
      "Horsepower            float64\n",
      "RPM                   float64\n",
      "Rev.per.mile          float64\n",
      "Man.trans.avail        object\n",
      "Fuel.tank.capacity    float64\n",
      "Passengers            float64\n",
      "Length                float64\n",
      "Wheelbase             float64\n",
      "Width                 float64\n",
      "Turn.circle           float64\n",
      "Rear.seat.room        float64\n",
      "Luggage.room          float64\n",
      "Weight                float64\n",
      "Origin                 object\n",
      "Make                   object\n",
      "dtype: object\n",
      "float64    18\n",
      "object      9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "#  number of rows and columns\n",
    "print(df.shape)\n",
    "\n",
    "# datatypes\n",
    "print(df.dtypes)\n",
    "\n",
    "# how many columns under each dtype\n",
    "# print(df.get_dtype_counts())\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# summary statistics\n",
    "df_stats = df.describe()\n",
    "\n",
    "# numpy array \n",
    "df_arr = df.values\n",
    "\n",
    "# list\n",
    "df_list = df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38. How to extract the row and column number of a particular cell with given criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(61.9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "# df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "# Get Manufacturer with highest price\n",
    "df.loc[df.Price == np.max(df.Price), ['Manufacturer', 'Model', 'Type']]\n",
    "\n",
    "# Get Row and Column number\n",
    "row, col = np.where(df.values == np.max(df.Price))\n",
    "\n",
    "# Get the value\n",
    "df.iat[row[0], col[0]]\n",
    "df.iloc[row[0], col[0]]\n",
    "\n",
    "# Alternates\n",
    "df.at[row[0], 'Price']\n",
    "df.at[row[0], 'Price']\n",
    "\n",
    "# The difference between `iat` - `iloc` vs `at` - `loc` is:\n",
    "# `iat` snd `iloc` accepts row and column numbers. \n",
    "# Whereas `at` and `loc` accepts index and column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39. How to rename a specific columns in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
      "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
      "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "# print(df.columns)\n",
    "df=df.rename(columns = {'Type':'CarType'})\n",
    "# or\n",
    "df.columns.values[2] = \"CarType\"\n",
    "\n",
    "# Step 2:\n",
    "df.columns = df.columns.map(lambda x: x.replace('.', '_'))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40. How to check if a dataframe has any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Manufacturer           4\n",
       "Model                  1\n",
       "Type                   3\n",
       "Min.Price              7\n",
       "Price                  2\n",
       "Max.Price              5\n",
       "MPG.city               9\n",
       "MPG.highway            2\n",
       "AirBags               38\n",
       "DriveTrain             7\n",
       "Cylinders              5\n",
       "EngineSize             2\n",
       "Horsepower             7\n",
       "RPM                    3\n",
       "Rev.per.mile           6\n",
       "Man.trans.avail        5\n",
       "Fuel.tank.capacity     8\n",
       "Passengers             2\n",
       "Length                 4\n",
       "Wheelbase              1\n",
       "Width                  6\n",
       "Turn.circle            5\n",
       "Rear.seat.room         4\n",
       "Luggage.room          19\n",
       "Weight                 7\n",
       "Origin                 5\n",
       "Make                   3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41. How to count the number of missing values in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "n_missings_each_col = df.apply(lambda x: x.isnull().sum())\n",
    "a=n_missings_each_col.argmax()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42. How to replace missing values of multiple numeric columns with the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min.Price  Max.Price\n",
      "0  12.900000  18.800000\n",
      "1  29.200000  38.700000\n",
      "2  25.900000  32.300000\n",
      "3  17.118605  44.600000\n",
      "4  17.118605  21.459091\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "df_out = df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x: x.fillna(x.mean()))\n",
    "print(df_out.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "43. How to use apply function on existing columns with global variables as additional arguments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "d = {'Min.Price': np.nanmean, 'Max.Price': np.nanmedian}\n",
    "df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x, d: x.fillna(d[x.name](x)), args=(d, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "44. How to select a specific column from a dataframe as a dataframe instead of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "type(df[['a']])\n",
    "type(df.loc[:, ['a']])\n",
    "type(df.iloc[:, [1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45. How to change the order of columns of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d   e\n",
      "0   0   1   2   3   4\n",
      "1   5   6   7   8   9\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n",
      "\n",
      "    a   b   c   d   e\n",
      "0   2   1   0   3   4\n",
      "1   7   6   5   8   9\n",
      "2  12  11  10  13  14\n",
      "3  17  16  15  18  19\n",
      "\n",
      "    b   d   e   a   c\n",
      "0   1   3   4   2   0\n",
      "1   6   8   9   7   5\n",
      "2  11  13  14  12  10\n",
      "3  16  18  19  17  15\n",
      "\n",
      "    e   d   c   b   a\n",
      "0   4   3   0   1   2\n",
      "1   9   8   5   6   7\n",
      "2  14  13  10  11  12\n",
      "3  19  18  15  16  17\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "print(df)\n",
    "df[\"a\"],df[\"c\"]=df[\"c\"],df[\"a\"]\n",
    "print()\n",
    "print(df)\n",
    "print()\n",
    "def interchange_columns(df, col1, col2):\n",
    "    df = df[[col for col in df.columns if col not in [col1, col2]] + [col1, col2]]\n",
    "    return df\n",
    "\n",
    "# Usage example\n",
    "df = interchange_columns(df, 'a', 'c')\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "df = df[sorted(df.columns, reverse=True)]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "46. How to set the number of rows and columns displayed in the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type  Min.Price  Price  ...  Rear.seat.room  \\\n",
      "0         Acura  Integra    Small       12.9   15.9  ...            26.5   \n",
      "1           NaN   Legend  Midsize       29.2   33.9  ...            30.0   \n",
      "2          Audi       90  Compact       25.9   29.1  ...            28.0   \n",
      "3          Audi      100  Midsize        NaN   37.7  ...            31.0   \n",
      "4           BMW     535i  Midsize        NaN   30.0  ...            27.0   \n",
      "..          ...      ...      ...        ...    ...  ...             ...   \n",
      "88   Volkswagen  Eurovan      Van       16.6   19.7  ...            34.0   \n",
      "89   Volkswagen   Passat  Compact       17.6   20.0  ...            31.5   \n",
      "90   Volkswagen  Corrado   Sporty       22.9   23.3  ...            26.0   \n",
      "91        Volvo      240  Compact       21.8   22.7  ...            29.5   \n",
      "92          NaN      850  Midsize       24.8   26.7  ...            30.0   \n",
      "\n",
      "    Luggage.room  Weight   Origin                Make  \n",
      "0            NaN  2705.0  non-USA       Acura Integra  \n",
      "1           15.0  3560.0  non-USA        Acura Legend  \n",
      "2           14.0  3375.0  non-USA             Audi 90  \n",
      "3           17.0  3405.0  non-USA            Audi 100  \n",
      "4           13.0  3640.0  non-USA            BMW 535i  \n",
      "..           ...     ...      ...                 ...  \n",
      "88           NaN  3960.0      NaN  Volkswagen Eurovan  \n",
      "89          14.0  2985.0  non-USA   Volkswagen Passat  \n",
      "90          15.0  2810.0  non-USA  Volkswagen Corrado  \n",
      "91          14.0  2985.0  non-USA           Volvo 240  \n",
      "92          15.0  3245.0  non-USA           Volvo 850  \n",
      "\n",
      "[93 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "# Now when you print the DataFrame, it will show a maximum of 10 rows and 10 columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47. How to format or suppress scientific notations in a pandas dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   random\n",
      "0  0.0000\n",
      "1  0.0148\n",
      "2  0.0314\n",
      "3  0.0000\n"
     ]
    }
   ],
   "source": [
    "# Create the DataFrame\n",
    "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n",
    "\n",
    "# Suppress scientific notation and format to 4 decimal places\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "48. How to format all the values in a dataframe as percentages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   random\n",
      "0  52.19%\n",
      "1  89.77%\n",
      "2  20.79%\n",
      "3  81.99%\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "\n",
    "# Format the values in the 'random' column as percentages\n",
    "df['random'] = df['random'].apply(lambda x: f\"{x * 100:.2f}%\")\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "49. How to filter every nth row in a dataframe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type\n",
      "0         Acura  Integra    Small\n",
      "20     Chrysler  LeBaron  Compact\n",
      "40        Honda  Prelude   Sporty\n",
      "60      Mercury   Cougar  Midsize\n",
      "80       Subaru   Loyale    Small\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Filter every 20th row starting from the 1st row (row 0)\n",
    "filtered_df = df.iloc[::20][['Manufacturer', 'Model', 'Type']]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50. How to create a primary key index by combining relevant columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Manufacturer    Model     Type  Min.Price  Max.Price\n",
      "PrimaryKey                                                                    \n",
      "Acura_Integra_Small              Acura  Integra    Small    12.9000    18.8000\n",
      "missing_Legend_Midsize         missing   Legend  Midsize    29.2000    38.7000\n",
      "Audi_90_Compact                   Audi       90  Compact    25.9000    32.3000\n",
      "Audi_100_Midsize                  Audi      100  Midsize        NaN    44.6000\n",
      "BMW_535i_Midsize                   BMW     535i  Midsize        NaN        NaN\n",
      "...                                ...      ...      ...        ...        ...\n",
      "Volkswagen_Eurovan_Van      Volkswagen  Eurovan      Van    16.6000    22.7000\n",
      "Volkswagen_Passat_Compact   Volkswagen   Passat  Compact    17.6000    22.4000\n",
      "Volkswagen_Corrado_Sporty   Volkswagen  Corrado   Sporty    22.9000    23.7000\n",
      "Volvo_240_Compact                Volvo      240  Compact    21.8000    23.5000\n",
      "missing_850_Midsize            missing      850  Midsize    24.8000    28.5000\n",
      "\n",
      "[93 rows x 5 columns]\n",
      "\n",
      "Is the index a primary key?  True\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0, 1, 2, 3, 5])\n",
    "\n",
    "# Replace NaNs with 'missing' in the specified columns\n",
    "df[['Manufacturer', 'Model', 'Type']] = df[['Manufacturer', 'Model', 'Type']].fillna('missing')\n",
    "\n",
    "# Create a new index by combining the three columns\n",
    "df['PrimaryKey'] = df['Manufacturer'] + '_' + df['Model'] + '_' + df['Type']\n",
    "df.set_index('PrimaryKey', inplace=True)\n",
    "\n",
    "# Check if the index is unique (to confirm it can be a primary key)\n",
    "is_unique = df.index.is_unique\n",
    "\n",
    "# Print the DataFrame with the new index and the uniqueness check\n",
    "print(df)\n",
    "print(\"\\nIs the index a primary key? \", is_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "51. How to get the row number of the nth largest value in a column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "     a   b   c\n",
      "0  16  14  21\n",
      "1   1  12  10\n",
      "2   9   7  16\n",
      "3  25  11  25\n",
      "4  18   3  24\n",
      "5  21   5   7\n",
      "6  19  16  24\n",
      "7  28  20   4\n",
      "8  15   4  27\n",
      "9   8  20  27\n",
      "The row position of the 5th largest value in column 'a' is: 4\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10, -1), columns=list('abc'))\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"DataFrame:\\n\", df)\n",
    "\n",
    "# Find the row position of the 5th largest value in column 'a'\n",
    "n = 5\n",
    "row_position = df['a'].nlargest(n).index[-1]\n",
    "\n",
    "# Print the row position\n",
    "print(f\"The row position of the {n}th largest value in column 'a' is: {row_position}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "52. How to find the position of the nth largest value greater than a given value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series:\n",
      " 0     22\n",
      "1     80\n",
      "2     89\n",
      "3     57\n",
      "4     40\n",
      "      ..\n",
      "10    36\n",
      "11    85\n",
      "12    32\n",
      "13     5\n",
      "14    95\n",
      "Length: 15, dtype: int64\n",
      "The position of the 2th largest value greater than the mean (47.20) is: 2\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 100, 15))\n",
    "\n",
    "# Display the Series\n",
    "print(\"Series:\\n\", ser)\n",
    "\n",
    "# Calculate the mean of the Series\n",
    "mean_value = ser.mean()\n",
    "\n",
    "# Find the 2nd largest value greater than the mean\n",
    "n = 2\n",
    "greater_than_mean = ser[ser > mean_value]\n",
    "\n",
    "# Check if there are enough values greater than the mean\n",
    "if len(greater_than_mean) >= n:\n",
    "    nth_largest_value = greater_than_mean.nlargest(n).iloc[-1]\n",
    "    position = ser[ser == nth_largest_value].index[0]\n",
    "    print(f\"The position of the {n}th largest value greater than the mean ({mean_value:.2f}) is: {position}\")\n",
    "else:\n",
    "    print(f\"There are not enough values greater than the mean ({mean_value:.2f}) to find the {n}th largest.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53. How to get the last n rows of a dataframe with row sum > 100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "         0       1       2       3       4\n",
      "0 19.4772 37.5673  5.4044 46.2351 35.1521\n",
      "1 22.8742 13.4369 44.8640 36.9360  6.3377\n",
      "2  2.4375 20.0304 16.9972 18.4557 41.3944\n",
      "3  4.7236  0.8923 16.8762 46.7345 37.6457\n",
      "4 27.0146  1.6861 31.9196  6.3409 25.2919\n",
      "5 37.2934 30.2530  5.2751 24.3968 39.8408\n",
      "6 19.4777 18.3682 45.4225  4.0004  9.0360\n",
      "7 26.5043 27.5425 37.9644 14.3159 47.9884\n",
      "8 18.5867 21.7720 37.2602 20.1120  8.7779\n",
      "9 10.0472 43.3514 20.6474 13.3082  8.6725\n",
      "\n",
      "Last two rows with row sum > 100:\n",
      "         0       1       2       3       4\n",
      "7 26.5043 27.5425 37.9644 14.3159 47.9884\n",
      "8 18.5867 21.7720 37.2602 20.1120  8.7779\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.random((10, 5)) * 50)  # Random values scaled to 50\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Calculate the row sums\n",
    "row_sums = df.sum(axis=1)\n",
    "\n",
    "# Filter the rows where the row sum is greater than 100\n",
    "filtered_df = df[row_sums > 100]\n",
    "\n",
    "# Get the last 2 rows of the filtered DataFrame\n",
    "last_n_rows = filtered_df.tail(2)\n",
    "\n",
    "# Print the result\n",
    "print(\"\\nLast two rows with row sum > 100:\\n\", last_n_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "54. How to find and cap outliers from a series or dataframe column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series:\n",
      " 0      0.0100\n",
      "1      0.0137\n",
      "2      0.0189\n",
      "3      0.0259\n",
      "4      0.0356\n",
      "       ...   \n",
      "25    28.0722\n",
      "26    38.5662\n",
      "27    52.9832\n",
      "28    72.7895\n",
      "29   100.0000\n",
      "Length: 30, dtype: float64\n",
      "\n",
      "Capped Series:\n",
      " 0     0.0160\n",
      "1     0.0160\n",
      "2     0.0189\n",
      "3     0.0259\n",
      "4     0.0356\n",
      "       ...  \n",
      "25   28.0722\n",
      "26   38.5662\n",
      "27   52.9832\n",
      "28   63.8767\n",
      "29   63.8767\n",
      "Length: 30, dtype: float64\n",
      "\n",
      "Lower 5th percentile: 0.016049294076965887\n",
      "Upper 95th percentile: 63.87667222018393\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.logspace(-2, 2, 30))\n",
    "\n",
    "# Display the original Series\n",
    "print(\"Original Series:\\n\", ser)\n",
    "\n",
    "# Calculate the 5th and 95th percentiles\n",
    "lower_bound = ser.quantile(0.05)\n",
    "upper_bound = ser.quantile(0.95)\n",
    "\n",
    "# Cap the outliers\n",
    "ser_capped = ser.copy()  # Make a copy to preserve original data\n",
    "ser_capped[ser_capped < lower_bound] = lower_bound\n",
    "ser_capped[ser_capped > upper_bound] = upper_bound\n",
    "\n",
    "# Print the capped Series\n",
    "print(\"\\nCapped Series:\\n\", ser_capped)\n",
    "\n",
    "# Optionally, display the bounds for reference\n",
    "print(f\"\\nLower 5th percentile: {lower_bound}\")\n",
    "print(f\"Upper 95th percentile: {upper_bound}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "55. How to reshape a dataframe to the largest possible square after removing the negative values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     0   1   2   3   4   5   6   7   8   9\n",
      "0  -1 -10  -8 -14  19   3   6  -2 -10  -2\n",
      "1  -7  21 -20  38  47  47  35 -11  42 -12\n",
      "2  33 -18  49  17  32   8   6  -8  -8  34\n",
      "3   1  36  38  26  41  46  -5   2  32  39\n",
      "4  14  44  -1  19  30  49  46  37  18  33\n",
      "5  24  10  20  -1  43 -18  33  19  18  22\n",
      "6  25   7  24 -12  -5   1  36   3 -11   1\n",
      "7 -17 -15   8  48  35   4  29   6  39 -19\n",
      "8  16  34  17  22   3  11   6  -8 -10  -1\n",
      "9  40  -6  47 -14  -6  11  34  -6  33 -15\n",
      "\n",
      "Reshaped DataFrame to largest possible square:\n",
      "     0   1   2   3   4   5   6   7\n",
      "0  19   3   6  21  38  47  47  35\n",
      "1  42  33  49  17  32   8   6  34\n",
      "2   1  36  38  26  41  46   2  32\n",
      "3  39  14  44  19  30  49  46  37\n",
      "4  18  33  24  10  20  43  33  19\n",
      "5  18  22  25   7  24   1  36   3\n",
      "6   1   8  48  35   4  29   6  39\n",
      "7  16  34  17  22   3  11   6  40\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10, -1))\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Flatten the DataFrame and filter out negative values\n",
    "positive_values = df.values[df.values >= 0]\n",
    "\n",
    "# Determine the size of the largest possible square\n",
    "n = int(np.floor(np.sqrt(len(positive_values))))\n",
    "\n",
    "# Create a new square DataFrame with the positive values\n",
    "reshaped_df = pd.DataFrame(positive_values[:n**2].reshape(n, n))\n",
    "\n",
    "# Display the reshaped DataFrame\n",
    "print(\"\\nReshaped DataFrame to largest possible square:\\n\", reshaped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "56. How to swap two rows of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     0   1   2   3   4\n",
      "0   0   1   2   3   4\n",
      "1   5   6   7   8   9\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n",
      "\n",
      "DataFrame after swapping rows 1 and 2:\n",
      "     0   1   2   3   4\n",
      "0   0   1   2   3   4\n",
      "1  10  11  12  13  14\n",
      "2   5   6   7   8   9\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Swap rows 1 and 2\n",
    "df.iloc[[1, 2]] = df.iloc[[2, 1]].values\n",
    "\n",
    "# Display the DataFrame after swapping\n",
    "print(\"\\nDataFrame after swapping rows 1 and 2:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "57. How to reverse the rows of a dataframe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     0   1   2   3   4\n",
      "0   0   1   2   3   4\n",
      "1   5   6   7   8   9\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n",
      "\n",
      "DataFrame after reversing the rows:\n",
      "     0   1   2   3   4\n",
      "0  20  21  22  23  24\n",
      "1  15  16  17  18  19\n",
      "2  10  11  12  13  14\n",
      "3   5   6   7   8   9\n",
      "4   0   1   2   3   4\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Reverse the rows of the DataFrame\n",
    "reversed_df = df[::-1].reset_index(drop=True)\n",
    "\n",
    "# Display the DataFrame after reversing the rows\n",
    "print(\"\\nDataFrame after reversing the rows:\\n\", reversed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58. How to create one-hot encodings of a categorical variable (dummy variables)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     a   b   c   d   e\n",
      "0   0   1   2   3   4\n",
      "1   5   6   7   8   9\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n",
      "\n",
      "DataFrame with one-hot encodings:\n",
      "        0      5     10     15     20   b   c   d   e\n",
      "0   True  False  False  False  False   1   2   3   4\n",
      "1  False   True  False  False  False   6   7   8   9\n",
      "2  False  False   True  False  False  11  12  13  14\n",
      "3  False  False  False   True  False  16  17  18  19\n",
      "4  False  False  False  False   True  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1), columns=list('abcde'))\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Get one-hot encodings for column 'a'\n",
    "one_hot = pd.get_dummies(df['a'])\n",
    "\n",
    "# Append the one-hot encodings to the original DataFrame\n",
    "df_with_dummies = pd.concat([one_hot, df.drop('a', axis=1)], axis=1)\n",
    "\n",
    "# Display the DataFrame with one-hot encodings\n",
    "print(\"\\nDataFrame with one-hot encodings:\\n\", df_with_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "59. Which column contains the highest number of row-wise maximum values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column with highest row maxes:  2\n"
     ]
    }
   ],
   "source": [
    "# df = pd.DataFrame(np.random.randint(1, 100, 40).reshape(10, -1))\n",
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1))\n",
    "# Display the original DataFrame\n",
    "print('Column with highest row maxes: ', df.apply(np.argmax, axis=1).value_counts().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60. How to create a new column that contains the row number of nearest column by euclidean distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "\n",
    "# Solution\n",
    "import numpy as np\n",
    "\n",
    "# init outputs\n",
    "nearest_rows = []\n",
    "nearest_distance = []\n",
    "\n",
    "# iterate rows.\n",
    "for i, row in df.iterrows():\n",
    "    curr = row\n",
    "    rest = df.drop(i)\n",
    "    e_dists = {}  # init dict to store euclidean dists for current row.\n",
    "    # iterate rest of rows for current row\n",
    "    for j, contestant in rest.iterrows():\n",
    "        # compute euclidean dist and update e_dists\n",
    "        e_dists.update({j: round(np.linalg.norm(curr.values - contestant.values))})\n",
    "    # update nearest row to current row and the distance value\n",
    "    nearest_rows.append(max(e_dists, key=e_dists.get))\n",
    "    nearest_distance.append(max(e_dists.values()))\n",
    "\n",
    "df['nearest_row'] = nearest_rows\n",
    "df['dist'] = nearest_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "61. How to know the maximum possible correlation value of each column against other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Correlation possible for each column:  [0.61 0.52 0.5  0.37 0.61 0.56 0.59 0.55 0.65 0.65]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))\n",
    "df\n",
    "\n",
    "# Solution\n",
    "abs_corrmat = np.abs(df.corr())\n",
    "max_corr = abs_corrmat.apply(lambda x: sorted(x)[-2])\n",
    "print('Maximum Correlation possible for each column: ', np.round(max_corr.tolist(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "62. How to create a column containing the minimum by maximum of each row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0.1522\n",
      "1   0.0568\n",
      "2   0.3222\n",
      "3   0.1414\n",
      "4   0.2500\n",
      "5   0.2444\n",
      "6   0.0256\n",
      "7   0.2083\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "# Solution 1\n",
    "min_by_max = df.apply(lambda x: np.min(x)/np.max(x), axis=1)\n",
    "\n",
    "# Solution 2\n",
    "min_by_max = np.min(df, axis=1)/np.max(df, axis=1)\n",
    "print(min_by_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "63. How to create a column that contains the penultimate value in each row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4  ...   6   7   8   9  penultimate\n",
      "0  75  71  99  62  51  ...  89  77  40  33           89\n",
      "1  33  47  12   1  14  ...  86  27  92  51           86\n",
      "2  42  98   2  10  99  ...  15  33  85  33           98\n",
      "3  83   1  36  67  64  ...  59  57   9  26           67\n",
      "4  26  12  44  91  92  ...   1  98  31  27           92\n",
      "5  58  13  86  78  26  ...  89  78   7  17           86\n",
      "6  89  94  38  40  55  ...   6  58  82  59           89\n",
      "7  44  48  55  77   2  ...  67  84  53  73           77\n",
      "\n",
      "[8 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "# Solution\n",
    "out = df.apply(lambda x: x.sort_values().unique()[-2], axis=1)\n",
    "df['penultimate'] = out\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64. How to normalize all columns in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1       2       3       4       5       6       7       8  \\\n",
      "0 -1.7000  1.5100  0.1900  1.5100 -1.5800 -0.5600 -1.2500 -1.1300 -0.4900   \n",
      "1  1.3000  0.5700  1.1400 -1.0400  0.6000  1.2800  0.4500 -0.0400  0.5800   \n",
      "2  0.4400 -0.5300  0.6400 -1.0400  1.1400  0.0400  0.2800  0.5300 -1.8400   \n",
      "3 -0.0500 -0.4300 -1.5100 -0.6400 -0.7300 -1.2700  1.1300  0.5600  0.9800   \n",
      "4  0.8100  1.1600 -1.0600  1.1100 -0.9100  0.1800  1.0200  1.1300 -0.6300   \n",
      "5 -1.2100 -1.4700 -0.1900 -0.2000  0.1100 -1.3800 -0.7200  1.1300  0.5800   \n",
      "6  0.3200 -0.2000  1.2600 -0.5000  1.2000  0.8900 -1.4300 -1.3800 -0.3100   \n",
      "7  0.0800 -0.6200 -0.4800  0.8000  0.1700  0.8200  0.5200 -0.8100  1.1200   \n",
      "\n",
      "        9  \n",
      "0  0.8500  \n",
      "1 -1.4300  \n",
      "2  0.5100  \n",
      "3  0.3600  \n",
      "4  1.1300  \n",
      "5  0.3900  \n",
      "6 -1.5200  \n",
      "7 -0.2900  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "# Solution Q1\n",
    "out1 = df.apply(lambda x: ((x - x.mean())/x.std()).round(2))\n",
    "print(out1)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "65. How to compute the correlation of each row with the suceeding row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.57),\n",
       " np.float64(-0.19),\n",
       " np.float64(-0.34),\n",
       " np.float64(-0.56),\n",
       " np.float64(-0.1),\n",
       " np.float64(-0.05),\n",
       " np.float64(0.55)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "# Solution\n",
    "[df.iloc[i].corr(df.iloc[i+1]).round(2) for i in range(df.shape[0])[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "66. How to replace both the diagonals of dataframe with 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0   0  15  48  44  54  57  97  87  28   0\n",
      "1  60   0  94  54  48  35  79  83   0  84\n",
      "2  32  74   0  75  30  93  42   0  66  16\n",
      "3  88  10   4   0  89  72   0  57  69  32\n",
      "4  37  96  31  46   0   0  40  23  47  70\n",
      "5  16  19  48  38   0   0  67  10  82  96\n",
      "6  56  83  30   0  11  33   0  66   7   5\n",
      "7  73  18   0  91   6   2  77   0  52  38\n",
      "8  32   0  29  10  83  59  57  60   0  54\n",
      "9   0  79  26  56  94  34  95  23  98   0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n",
    "\n",
    "# Solution\n",
    "for i in range(df.shape[0]):\n",
    "    df.iat[i, i] = 0\n",
    "    df.iat[df.shape[0]-i-1, i] = 0\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "67. How to get the particular group of a groupby dataframe by key?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6019/2610414853.py:8: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  df_grouped.get_group('apple')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.3775</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    col1   col2  col3\n",
       "0  apple 0.3775    10\n",
       "3  apple 0.0667    12\n",
       "6  apple 0.0681     4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'col2': np.random.rand(9),\n",
    "                   'col3': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df_grouped = df.groupby(['col1'])\n",
    "\n",
    "# # Solution 1\n",
    "df_grouped.get_group('apple')\n",
    "\n",
    "# # Solution 2\n",
    "# for i, dff in df_grouped:\n",
    "#     if i == 'apple':\n",
    "#         print(dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "68. How to get the n’th largest value of a column when grouped by another column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit  taste  price\n",
      "0   apple 0.7082      0\n",
      "1  banana 0.5014      8\n",
      "2  orange 0.6591     14\n",
      "3   apple 0.0440      3\n",
      "4  banana 0.4346      5\n",
      "5  orange 0.3087     14\n",
      "6   apple 0.0377      4\n",
      "7  banana 0.6571     11\n",
      "8  orange 0.8687      3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5013847587551664)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'taste': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Solution\n",
    "df_grpd = df['taste'].groupby(df.fruit)\n",
    "df_grpd.get_group('banana').sort_values().iloc[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "69. How to compute grouped mean on pandas dataframe and keep the grouped column as another column (not index)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit   price\n",
      "0   apple 10.6667\n",
      "1  banana 11.3333\n",
      "2  orange  4.6667\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "# Solution\n",
    "out = df.groupby('fruit', as_index=False)['price'].mean()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70. How to join two dataframes by 2 columns so they have only the common rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>weight</th>\n",
       "      <th>price_left</th>\n",
       "      <th>pazham</th>\n",
       "      <th>kilo</th>\n",
       "      <th>price_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>9</td>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>5</td>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>10</td>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>12</td>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fruit weight  price_left  pazham  kilo  price_right\n",
       "0   apple   high           9   apple  high           14\n",
       "1  orange    low           1  orange   low            7\n",
       "2   apple   high           5   apple  high           14\n",
       "3  orange    low           0  orange   low            7\n",
       "4   apple   high          10   apple  high           14\n",
       "5  orange    low          12  orange   low            7"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 6)})\n",
    "\n",
    "# Solution\n",
    "pd.merge(df1, df2, how='inner', left_on=['fruit', 'weight'], right_on=['pazham', 'kilo'], suffixes=['_left', '_right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "72. How to get the positions where values of two columns match?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 9]),)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n",
    "                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})\n",
    "\n",
    "# Solution\n",
    "np.where(df.fruit1 == df.fruit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73. How to create lags and leads of a column in a dataframe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d  a_lag1  b_lead1\n",
      "0  12  37  32  46     NaN  44.0000\n",
      "1  62  44  20  44 12.0000  11.0000\n",
      "2  52  11  58  62 62.0000  95.0000\n",
      "3  86  95  39  62 52.0000  32.0000\n",
      "4  50  32  78  27 86.0000      NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "\n",
    "# Solution\n",
    "df['a_lag1'] = df['a'].shift(1)\n",
    "df['b_lead1'] = df['b'].shift(-1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "74. How to get the frequency of unique values in the entire dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6019/52017146.py:4: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(df.values.ravel())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    5\n",
       "8    5\n",
       "4    3\n",
       "5    2\n",
       "6    2\n",
       "3    2\n",
       "7    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "\n",
    "# Solution\n",
    "pd.value_counts(df.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75. How to split a text column into two separate columns?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 STD            City    State\n",
      "1  33   Kolkata    West Bengal\n",
      "2  44    Chennai    Tamil Nadu\n",
      "3  40   Hyderabad    Telengana\n",
      "4  80   Bangalore    Karnataka\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\"STD, City    State\",\n",
    "\"33, Kolkata    West Bengal\",\n",
    "\"44, Chennai    Tamil Nadu\",\n",
    "\"40, Hyderabad    Telengana\",\n",
    "\"80, Bangalore    Karnataka\"], columns=['row'])\n",
    "\n",
    "# Solution\n",
    "df_out = df.row.str.split(',|\\t', expand=True)\n",
    "\n",
    "# Make first row as header\n",
    "new_header = df_out.iloc[0]\n",
    "df_out = df_out[1:]\n",
    "df_out.columns = new_header\n",
    "print(df_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
